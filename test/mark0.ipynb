{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "# import openpyxl\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 आदमीं को मारने पर गोडसे आतंकी हो सके है तो\\n...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Vishesh4: @jawaharyadavbjp जवाहर यादव, अगर...</td>\n",
       "      <td>NOT_HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही ...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yey nina khothani labafazi benu phambili Finis...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Rajeshbhanjan2: जब भी कोई सिकुलर कोंग्रेसी...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     task1\n",
       "0  1 आदमीं को मारने पर गोडसे आतंकी हो सके है तो\\n...      HATE\n",
       "1  RT @Vishesh4: @jawaharyadavbjp जवाहर यादव, अगर...  NOT_HATE\n",
       "2  RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही ...      HATE\n",
       "3  Yey nina khothani labafazi benu phambili Finis...      HATE\n",
       "4  RT @Rajeshbhanjan2: जब भी कोई सिकुलर कोंग्रेसी...      HATE"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wb = load_workbook(\"datasets/hindi.xlsx\")\n",
    "sheet = wb.active\n",
    "col = csv.writer(open(\"tt.csv\", 'w', newline=\"\"))\n",
    "for r in sheet.rows:\n",
    "    col.writerow([cell.value for cell in r])\n",
    "  \n",
    "df = pd.DataFrame(pd.read_csv(\"tt.csv\"))\n",
    "df.to_csv(\"datasets/hindi.csv\", sep=\",\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर सकते लेकिन बुरखा पहन के कर सकते हैं @yadavakhilesh ?\n",
      "\n",
      "ये आज़मगढ़ है और यहाँ से \"टोटी चोर\"…\n"
     ]
    }
   ],
   "source": [
    "df['task1'] = df['task1'].map({'HATE':1, 'NOT_HATE':0})\n",
    "df.head()\n",
    "print(df[\"text\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'तेरा', 'बहि', 'अदि', 'उन', 'अपनी', 'द्वारा', 'निहायत', 'यहां', 'तुझे', 'इसी', 'साभ', 'ने', 'हें', 'करना', 'इसके', 'कोइ', 'उन्ह', 'मेरी', 'तिंहों', 'आदि', 'वहाँ', 'कोनसा', 'तिन्हों', 'था', 'जिन्हें', 'लिए', 'वे', 'ओर', 'सो', 'किन्हें', 'मगर', 'कोन', 'किंहों', 'तू', 'वर्ग', 'अभी', 'काफि', 'सब', 'वुह', 'पास', 'एसे', 'उसे', 'मैं', 'उसका', 'हूं', 'कहते', 'किन्हों', 'ये', 'जब', 'जिंहों', 'लिये', 'होती', 'तेरी', 'इन', 'इसका', 'इस', 'जिस', 'अपने', 'मानो', 'एवं', 'रवासा', 'व', 'उसने', 'जा', 'अभि', 'जिंहें', 'का', 'काफ़ी', 'आप', 'जहां', 'तक', 'वहीं', 'यदि', 'जेसा', 'वह ', 'ले', 'निचे', 'इंहिं', 'एस', 'बिलकुल', 'संग', 'उसकी', 'भितर', 'अंदर', 'रखें', 'में', 'कहता', 'वाले', 'इंहें', 'कुल', 'कुछ', 'इसे', 'दुसरा', 'लेकिन', 'रह', 'हुआ', 'बही', 'उन्हीं', 'दिया', 'उनको', 'इसलिये', 'हम', 'वह', 'कौन', 'जो', 'तब', 'हैं', 'कइ', 'कि', 'उसके', 'वहां', 'करते', 'उनका', 'कर', 'साथ', 'यिह', 'या', \"इतयादि' ,'यहाँ\", 'है', 'वहिं', 'गए', 'नहीं', 'दो', 'कई', 'अपना', 'जिसे', 'कह', 'उंहिं', 'जैसे', 'करें', 'मुझे', 'बाला', 'थि', 'पर  ', 'किया', 'के', 'किसी', 'गया', 'इन्हीं', 'तिसे', 'इंहों', 'देकर', 'इसकि', 'परन्तु', 'जिधर', 'किंहें', 'तेरे', 'उनके', 'नहिं', 'इत्यादि', 'तो', 'थे', 'जेसे', 'होने', 'जितना', 'हि', 'होति', 'भि', 'सकते', 'दबारा', 'फिर', 'उसी', 'दूसरे', 'एक', 'पर', 'घर', 'जीधर', 'उनकि', 'उन्हें', 'उसको', 'बनी', 'हो', 'हुए', 'इन्हें', 'सकता', 'वरग', 'यही', 'हुई', 'वुह ', 'अपनि', 'बाद', 'करने', 'मे', 'ऐसे', 'जिन', 'साबुत', 'तिंहें', 'से', 'किसि', 'कोई', 'दुसरे', 'इनका', 'और', 'तिन', 'पूरा', 'कौनसा', 'होना', 'वग़ैरह', 'जैसा', 'किस', 'मेरे', 'पे', 'हे', 'बनि', 'ही', 'तुम', 'ऱ्वासा', 'यहि', 'उसि', 'तिन्हें', 'उनकी', 'न', 'उंहें', 'सारा', 'उन्होंने', 'तुम्हारे', 'अप', 'करता', 'पहले', 'किसे', 'उंहों', 'अर्थात', 'उन्हों', 'दे', 'जहाँ', 'भीतर', 'साम्हने', 'क्या', 'नीचे', 'की', 'सभि', 'इन ', 'सभी', 'होते', 'इसमें', 'मुझ', 'अत', \"बात' \", 'किर', 'रहे', 'पुरा', 'भी', 'सबसे', 'उस', 'कितना', 'रहा', 'अनुसार', 'हुअ', 'यिह ', 'यह', 'जिन्हों', 'इन्हों', 'थी', 'इसकी', 'क्योंकि', 'कहा', 'दवारा', 'कारण', 'इसि', 'को', 'ना', 'ऐसा', 'हुइ', 'वगेरह', 'तिस', 'तरह', 'होता', 'बहुत'}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "with open(\"datasets/Hindi_StopWords.txt\",encoding='utf-8') as f:\n",
    "    stopword= f.read().strip('\\ufeff')\n",
    "stopword = stopword.split(\", \")\n",
    "stopword = [i.strip(\"'\") for i in stopword]\n",
    "\n",
    "stopwords = set(stopword)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आदमीं', 'को', 'मारने', 'पर', 'गोडसे', 'आतंकी', 'हो', 'सके', 'है', 'तो\\n17000', 'सिखो,', '5000', 'भोपाली,', '3000', 'तमिलों', 'का', 'कत्लेआम', 'करवाने', 'वाला']\n",
      "\n",
      "Number of words: 20755\n",
      "\n",
      "['@Vishesh4:', '@jawaharyadavbjp', 'जवाहर', 'यादव,', 'अगर', 'हिम्मत', 'है', 'तो', 'पूरा', 'वीडियो', 'डालो', 'फिर', 'तुम्हारे', 'झूठ', 'सामने', 'आएंगे।\\nदीपेंदर', 'ने', 'साफ', 'कहा,']\n",
      "\n",
      "Number of words: 46752\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "hate_det = df[df.task1==1]\n",
    "hate_det.reset_index(drop=True, inplace=True)\n",
    "acc_det = df[df.task1==0]\n",
    "acc_det.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Tokenization\n",
    "hate_news = []\n",
    "for rows in range(0, hate_det.shape[0]):\n",
    "    head_txt = hate_det.text[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    hate_news.append(head_txt)\n",
    "\n",
    "hate_list = list(itertools.chain(*hate_news))\n",
    "print(hate_list[1:20])\n",
    "print(\"\\n\" + \"Number of words: \" + str(len(hate_list)))\n",
    "acc_news = []\n",
    "for rows in range(0, acc_det.shape[0]):\n",
    "    head_txt = acc_det.text[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    acc_news.append(head_txt)\n",
    "\n",
    "acc_list = list(itertools.chain(*acc_news))\n",
    "print(\"\\n\" + str(acc_list[1:20]))\n",
    "print(\"\\n\" + \"Number of words: \" + str(len(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "Y = df.task1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2537    नहीं कोई बात होती फिर भी बात होती है,\\nकुछ रिश...\n",
       "1384    RT @Aastha9305: बनारस से भी ज्यादा दिलचस्प सीट...\n",
       "1301    RT @RoflNana_: डाक्टर आप को डॉक्टर बन्ने के लि...\n",
       "372     जो नाले से गैस बत्तख से ऑक्सीजन और गोबर से कोह...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
    "tk.fit_on_texts(X_train)\n",
    "seqs = tk.texts_to_sequences(X_train)\n",
    "max_len = 100\n",
    "seqs_mat = tf.keras.preprocessing.sequence.pad_sequences(seqs,maxlen=max_len)\n",
    "X_train[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_def():\n",
    "    inputs = tf.keras.layers.Input(name='inputs', shape=[max_len])\n",
    "    layer = tf.keras.layers.Embedding(1000,50,input_length=max_len)(inputs)\n",
    "    layer = tf.keras.layers.LSTM(64)(layer)\n",
    "    layer = tf.keras.layers.Dense(256,name='FC1')(layer)\n",
    "    layer = tf.keras.layers.Activation('relu')(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.2)(layer)\n",
    "    layer = tf.keras.layers.Dense(1,name='out_layer')(layer)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/drex/.local/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/drex/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_def()\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2124 samples, validate on 236 samples\n",
      "WARNING:tensorflow:From /home/drex/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "2124/2124 [==============================] - 12s 6ms/sample - loss: 0.6867 - acc: 0.7024 - val_loss: 0.5965 - val_acc: 0.7076\n",
      "Epoch 2/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.5931 - acc: 0.7331 - val_loss: 0.5948 - val_acc: 0.6907\n",
      "Epoch 3/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.4769 - acc: 0.7830 - val_loss: 0.6899 - val_acc: 0.6780\n",
      "Epoch 4/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.3862 - acc: 0.8475 - val_loss: 1.0268 - val_acc: 0.6695\n",
      "Epoch 5/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.4306 - acc: 0.8413 - val_loss: 2.9805 - val_acc: 0.5297\n",
      "Epoch 6/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.5291 - acc: 0.7830 - val_loss: 0.7894 - val_acc: 0.6186\n",
      "Epoch 7/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.4215 - acc: 0.8041 - val_loss: 0.9754 - val_acc: 0.6949\n",
      "Epoch 8/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.4016 - acc: 0.8734 - val_loss: 1.1239 - val_acc: 0.6780\n",
      "Epoch 9/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.3644 - acc: 0.8828 - val_loss: 2.0106 - val_acc: 0.6737\n",
      "Epoch 10/10\n",
      "2124/2124 [==============================] - 9s 4ms/sample - loss: 0.3905 - acc: 0.8517 - val_loss: 1.8249 - val_acc: 0.6695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2fc6073e48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc', \n",
    "    mode='max',\n",
    "    patience=10\n",
    ")\n",
    "# increase epochs and other steps for better training\n",
    "model.fit(seqs_mat,Y_train,batch_size=100,epochs=10,\n",
    "          validation_split=0.1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 2s 3ms/sample - loss: 2.0797 - acc: 0.6734\n",
      "Test set\n",
      "  Loss: 2.080\n",
      "  Accuracy: 0.673\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tk.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = tf.keras.preprocessing.sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hate(user_seq):\n",
    "#     prediction\n",
    "    prob = model.predict(user_seq)\n",
    "    probability = np.mean(prob, axis=0)\n",
    "\n",
    "    if probability > 0.5:\n",
    "        return(\"Hate\")\n",
    "    elif probability < 0.5:\n",
    "        return(\"Not Hate\")\n",
    "    elif probability == 0.5:\n",
    "        return(\"Neutral\")\n",
    "\n",
    "def user_text_processing(user_text):\n",
    "    user_text = user_text.split()\n",
    "    user_text = [word.lower() for word in user_text if word not in stopwords]\n",
    "#     user_text = [lemm.lemmatize(word) for word in user_text]\n",
    "    user_text\n",
    "    user_seq = np.array(user_text)\n",
    "    user_seq = tk.texts_to_sequences(user_seq)\n",
    "    user_seq = tf.keras.preprocessing.sequence.pad_sequences(user_seq,maxlen=max_len)\n",
    "\n",
    "    return user_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर सकते लेकिन बुरखा पहन के कर सकते हैं @yadavakhilesh ? ये आज़मगढ़ है और यहाँ से \"टोटी चोर\"…' is of 'Not Hate' nature\n"
     ]
    }
   ],
   "source": [
    "user_text = 'RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर सकते लेकिन बुरखा पहन के कर सकते हैं @yadavakhilesh ? ये आज़मगढ़ है और यहाँ से \"टोटी चोर\"…'\n",
    "user_seq = user_text_processing(user_text)\n",
    "user_seq\n",
    "prediction = predict_hate(user_seq)\n",
    "print(f\"Sentence '{user_text}' is of '{prediction}' nature\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
