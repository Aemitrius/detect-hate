{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "# import openpyxl\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 आदमीं को मारने पर गोडसे आतंकी हो सके है तो\\n...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Vishesh4: @jawaharyadavbjp जवाहर यादव, अगर...</td>\n",
       "      <td>NOT_HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही ...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yey nina khothani labafazi benu phambili Finis...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Rajeshbhanjan2: जब भी कोई सिकुलर कोंग्रेसी...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     task1\n",
       "0  1 आदमीं को मारने पर गोडसे आतंकी हो सके है तो\\n...      HATE\n",
       "1  RT @Vishesh4: @jawaharyadavbjp जवाहर यादव, अगर...  NOT_HATE\n",
       "2  RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही ...      HATE\n",
       "3  Yey nina khothani labafazi benu phambili Finis...      HATE\n",
       "4  RT @Rajeshbhanjan2: जब भी कोई सिकुलर कोंग्रेसी...      HATE"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wb = load_workbook(\"datasets/hindi.xlsx\")\n",
    "sheet = wb.active\n",
    "col = csv.writer(open(\"tt.csv\", 'w', newline=\"\"))\n",
    "for r in sheet.rows:\n",
    "    col.writerow([cell.value for cell in r])\n",
    "  \n",
    "df = pd.DataFrame(pd.read_csv(\"tt.csv\"))\n",
    "df.to_csv(\"datasets/hindi.csv\", sep=\",\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 आदमीं को मारने पर गोडसे आतंकी हो सके है तो\\n...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Vishesh4: @jawaharyadavbjp जवाहर यादव, अगर ह...</td>\n",
       "      <td>NOT_HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yey nina khothani labafazi benu phambili Finis...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Rajeshbhanjan2: जब भी कोई सिकुलर कोंग्रेसी ग...</td>\n",
       "      <td>HATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     task1\n",
       "0  1 आदमीं को मारने पर गोडसे आतंकी हो सके है तो\\n...      HATE\n",
       "1   @Vishesh4: @jawaharyadavbjp जवाहर यादव, अगर ह...  NOT_HATE\n",
       "2   @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर...      HATE\n",
       "3  Yey nina khothani labafazi benu phambili Finis...      HATE\n",
       "4   @Rajeshbhanjan2: जब भी कोई सिकुलर कोंग्रेसी ग...      HATE"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].map(lambda x: x.lstrip('RT@').rstrip('RT@'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर सकते लेकिन बुरखा पहन के कर सकते हैं @yadavakhilesh ?\n",
      "\n",
      "ये आज़मगढ़ है और यहाँ से \"टोटी चोर\"…\n"
     ]
    }
   ],
   "source": [
    "df['task1'] = df['task1'].map({'HATE':1, 'NOT_HATE':0})\n",
    "df.head()\n",
    "print(df[\"text\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'इसकी', 'कई', 'इन', 'बिलकुल', \"इतयादि' ,'यहाँ\", 'अप', 'द्वारा', 'ना', 'बाद', 'हे', 'तिस', 'कहते', 'जिन्हों', 'किस', 'कौन', 'होता', 'सारा', 'वहिं', 'कहा', 'घर', 'फिर', 'उनको', 'दूसरे', 'हुइ', 'अर्थात', 'ने', 'तुझे', 'क्योंकि', 'उनका', 'दबारा', 'का', 'मानो', 'अत', 'जैसा', 'ओर', 'उसी', 'निचे', 'वुह', 'वह ', 'लिये', 'तब', 'पहले', 'नहिं', 'उनकि', 'एक', 'किसि', 'यिह', 'किन्हें', 'हम', 'साबुत', 'वुह ', 'जेसा', 'रह', 'संग', 'मुझ', 'उनकी', 'ऱ्वासा', 'ही', 'एस', 'सभी', 'वगेरह', 'एसे', 'हुअ', 'तुम', 'यदि', 'जितना', 'कौनसा', 'यहि', 'करता', 'या', 'मेरी', 'वहां', 'अदि', 'तेरा', 'पर  ', 'इनका', 'और', 'साथ', 'तेरे', 'तिसे', 'किसे', 'जा', 'उसने', 'न', 'इसकि', 'तिन्हों', 'तेरी', 'उन्ह', 'होने', 'अपना', 'होना', 'रहे', 'किया', 'जिंहें', 'इंहिं', 'गए', 'जिसे', 'हें', 'पूरा', 'वह', 'उन्हीं', 'अपनि', 'पे', 'उसकी', 'तक', 'काफि', 'दुसरे', 'अपनी', 'होते', 'उसे', 'इसलिये', 'किंहें', 'तिंहें', 'कह', 'इत्यादि', 'यह', 'कोन', 'मैं', 'मगर', 'जो', 'थी', 'उसका', 'इन्हें', 'उन', 'कोनसा', 'भितर', 'उंहों', 'कइ', 'ऐसे', 'मेरे', 'नीचे', 'ले', 'आप', 'हुए', 'किसी', 'बही', 'करें', 'अनुसार', 'किर', 'सब', 'आदि', 'हुई', 'मुझे', 'जिन्हें', 'तू', 'हुआ', 'वाले', 'सो', 'व', 'यही', 'बनी', 'जिधर', 'वरग', 'रहा', 'दो', 'इंहों', 'बाला', 'तिंहों', 'पुरा', 'होती', 'क्या', 'कि', 'तरह', 'जहां', 'अभी', 'अपने', 'नहीं', 'दुसरा', 'के', 'रवासा', 'कुछ', 'इसमें', 'सभि', \"बात' \", 'करने', 'जेसे', 'से', 'काफ़ी', 'वहीं', 'उन्हों', 'इन्हों', 'इन ', 'देकर', 'ये', 'रखें', 'निहायत', 'इसका', 'कोई', 'पर', 'कर', 'जिंहों', 'दिया', 'साभ', 'उंहिं', 'करना', 'जहाँ', 'करते', 'दे', 'अंदर', 'किंहों', 'वे', 'जब', 'जीधर', 'तिन', 'इंहें', 'तुम्हारे', 'इसके', 'इस', 'जिस', 'लेकिन', 'परन्तु', 'लिए', 'कोइ', 'कहता', 'साम्हने', 'उंहें', 'जिन', 'भी', 'की', 'बहि', 'दवारा', 'इन्हीं', 'उसि', 'किन्हों', 'अभि', 'गया', 'भि', 'हि', 'उन्होंने', 'को', 'वहाँ', 'इसि', 'यहां', 'उनके', 'बनि', 'मे', 'सबसे', 'इसी', 'उसके', 'में', 'उन्हें', 'इसे', 'वग़ैरह', 'तिन्हें', 'एवं', 'था', 'कुल', 'कितना', 'कारण', 'ऐसा', 'भीतर', 'सकता', 'है', 'बहुत', 'पास', 'हो', 'वर्ग', 'तो', 'हैं', 'जैसे', 'उस', 'होति', 'यिह ', 'हूं', 'थे', 'थि', 'उसको', 'सकते'}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "with open(\"datasets/Hindi_StopWords.txt\",encoding='utf-8') as f:\n",
    "    stopword= f.read().strip('\\ufeff')\n",
    "stopword = stopword.split(\", \")\n",
    "stopword = [i.strip(\"'\") for i in stopword]\n",
    "\n",
    "stopwords = set(stopword)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['आदमीं', 'को', 'मारने', 'पर', 'गोडसे', 'आतंकी', 'हो', 'सके', 'है', 'तो\\n17000', 'सिखो,', '5000', 'भोपाली,', '3000', 'तमिलों', 'का', 'कत्लेआम', 'करवाने', 'वाला']\n",
      "\n",
      "Number of words: 20806\n",
      "\n",
      "['@Vishesh4:', '@jawaharyadavbjp', 'जवाहर', 'यादव,', 'अगर', 'हिम्मत', 'है', 'तो', 'पूरा', 'वीडियो', 'डालो', 'फिर', 'तुम्हारे', 'झूठ', 'सामने', 'आएंगे।\\nदीपेंदर', 'ने', 'साफ', 'कहा,']\n",
      "\n",
      "Number of words: 46970\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "hate_det = df[df.task1==1]\n",
    "hate_det.reset_index(drop=True, inplace=True)\n",
    "acc_det = df[df.task1==0]\n",
    "acc_det.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Tokenization\n",
    "hate_news = []\n",
    "for rows in range(0, hate_det.shape[0]):\n",
    "    head_txt = hate_det.text[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    hate_news.append(head_txt)\n",
    "\n",
    "hate_list = list(itertools.chain(*hate_news))\n",
    "print(hate_list[1:20])\n",
    "print(\"\\n\" + \"Number of words: \" + str(len(hate_list)))\n",
    "acc_news = []\n",
    "for rows in range(0, acc_det.shape[0]):\n",
    "    head_txt = acc_det.text[rows]\n",
    "    head_txt = head_txt.split(\" \")\n",
    "    acc_news.append(head_txt)\n",
    "\n",
    "acc_list = list(itertools.chain(*acc_news))\n",
    "print(\"\\n\" + str(acc_list[1:20]))\n",
    "print(\"\\n\" + \"Number of words: \" + str(len(acc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "Y = df.task1\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1364    BKaurDeep मोदी ने IPL का कप धोनी से छीन कर अम्...\n",
       "2898     @ViShNuKeer18: #Allah_Kabir\\nकबीर जी ने समझाय...\n",
       "216     Jitendr14272284 @Pinkimishr क्या आपने किसी मुस...\n",
       "786      @MKS1703: इस बन्दे ने साबित कर दिया कि इंसानि...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
    "tk.fit_on_texts(X_train)\n",
    "seqs = tk.texts_to_sequences(X_train)\n",
    "max_len = 100\n",
    "seqs_mat = tf.keras.preprocessing.sequence.pad_sequences(seqs,maxlen=max_len)\n",
    "X_train[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_def():\n",
    "    inputs = tf.keras.layers.Input(name='inputs', shape=[max_len])\n",
    "    layer = tf.keras.layers.Embedding(1000,50,input_length=max_len)(inputs)\n",
    "    layer = tf.keras.layers.LSTM(64)(layer)\n",
    "    layer = tf.keras.layers.Dense(256,name='FC1')(layer)\n",
    "    layer = tf.keras.layers.Activation('relu')(layer)\n",
    "    layer = tf.keras.layers.Dropout(0.2)(layer)\n",
    "    layer = tf.keras.layers.Dense(1,name='out_layer')(layer)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 96,337\n",
      "Trainable params: 96,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_def()\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2133 samples, validate on 237 samples\n",
      "Epoch 1/25\n",
      "2133/2133 [==============================] - 8s 4ms/sample - loss: 0.7438 - acc: 0.7037 - val_loss: 0.5521 - val_acc: 0.7511\n",
      "Epoch 2/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.5418 - acc: 0.7623 - val_loss: 1.0164 - val_acc: 0.7468\n",
      "Epoch 3/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.5108 - acc: 0.8186 - val_loss: 1.4022 - val_acc: 0.7426\n",
      "Epoch 4/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.4598 - acc: 0.8594 - val_loss: 1.7488 - val_acc: 0.7384\n",
      "Epoch 5/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.4048 - acc: 0.8748 - val_loss: 2.1271 - val_acc: 0.7257\n",
      "Epoch 6/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.3807 - acc: 0.9067 - val_loss: 2.4914 - val_acc: 0.7215\n",
      "Epoch 7/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.4842 - acc: 0.9058 - val_loss: 2.8704 - val_acc: 0.7004\n",
      "Epoch 8/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.7325 - acc: 0.7384 - val_loss: 1.6235 - val_acc: 0.7426\n",
      "Epoch 9/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.5919 - acc: 0.8012 - val_loss: 0.9341 - val_acc: 0.7046\n",
      "Epoch 10/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.4640 - acc: 0.8429 - val_loss: 0.9326 - val_acc: 0.6371\n",
      "Epoch 11/25\n",
      "2133/2133 [==============================] - 6s 3ms/sample - loss: 0.4367 - acc: 0.8354 - val_loss: 1.0845 - val_acc: 0.7511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa86f565c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_acc', \n",
    "    mode='max',\n",
    "    patience=10\n",
    ")\n",
    "# increase epochs and other steps for better training\n",
    "model.fit(seqs_mat,Y_train,batch_size=100,epochs=25,\n",
    "          validation_split=0.1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593/593 [==============================] - 1s 1ms/sample - loss: 1.1266 - acc: 0.7083\n",
      "Test set\n",
      "  Loss: 1.127\n",
      "  Accuracy: 0.708\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tk.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = tf.keras.preprocessing.sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "\n",
    "accr = model.evaluate(test_sequences_matrix,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hate(user_seq):\n",
    "#     prediction\n",
    "    prob = model.predict(user_seq)\n",
    "    probability = np.mean(prob, axis=0)\n",
    "\n",
    "    if probability > 0.5:\n",
    "        return(\"Hate\")\n",
    "    elif probability < 0.5:\n",
    "        return(\"Not Hate\")\n",
    "    elif probability == 0.5:\n",
    "        return(\"Neutral\")\n",
    "\n",
    "def user_text_processing(user_text):\n",
    "    user_text = user_text.split()\n",
    "    user_text = [word.lower() for word in user_text if word not in stopwords]\n",
    "#     user_text = [lemm.lemmatize(word) for word in user_text]\n",
    "    user_text\n",
    "    user_seq = np.array(user_text)\n",
    "    user_seq = tk.texts_to_sequences(user_seq)\n",
    "    user_seq = tf.keras.preprocessing.sequence.pad_sequences(user_seq,maxlen=max_len)\n",
    "\n",
    "    return user_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर सकते लेकिन बुरखा पहन के कर सकते हैं @yadavakhilesh ? ये आज़मगढ़ है और यहाँ से \"टोटी चोर\"…' is of 'Not Hate' nature\n"
     ]
    }
   ],
   "source": [
    "user_text = 'RT @FunKeyBaat: #भगवा वस्त्र पहन कर मतदान नही कर सकते लेकिन बुरखा पहन के कर सकते हैं @yadavakhilesh ? ये आज़मगढ़ है और यहाँ से \"टोटी चोर\"…'\n",
    "user_seq = user_text_processing(user_text)\n",
    "user_seq\n",
    "prediction = predict_hate(user_seq)\n",
    "print(f\"Sentence '{user_text}' is of '{prediction}' nature\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "train_texts, valid_texts, y_train, y_valid = train_test_split(df['text'], df['task1'], random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(ngram_range=(1, 2), max_features=50000, min_df=2)\n",
    "\n",
    "logit = LogisticRegression(C=1, n_jobs=4, solver='lbfgs', random_state=17, verbose=1)\n",
    "tfidf_logit_pipeline = Pipeline([('tf_idf', tf_idf), ('logit', logit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 369 ms, sys: 3.68 ms, total: 372 ms\n",
      "Wall time: 1.88 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf_idf',\n",
       "                 TfidfVectorizer(max_features=50000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('logit',\n",
       "                 LogisticRegression(C=1, n_jobs=4, random_state=17,\n",
       "                                    verbose=1))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_logit_pipeline.fit(train_texts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.4 ms, sys: 0 ns, total: 75.4 ms\n",
      "Wall time: 77.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_pred = tfidf_logit_pipeline.predict(valid_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7139001349527665"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'eli5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3f83338eaeaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m eli5.show_weights(estimator=tfidf_logit_pipeline.named_steps['logit'],\n\u001b[1;32m      3\u001b[0m                   vec=tfidf_logit_pipeline.named_steps['tf_idf'])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eli5'"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "eli5.show_weights(estimator=tfidf_logit_pipeline.named_steps['logit'], vec=tfidf_logit_pipeline.named_steps['tf_idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
